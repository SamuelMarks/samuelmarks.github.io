webpackJsonp([3],{NXee:function(l,n,u){"use strict";Object.defineProperty(n,"__esModule",{value:!0});var e=u("WT6e"),a=function(){},t=function(){function l(){}return l.prototype.ngOnInit=function(){},l}(),i=e._2({encapsulation:0,styles:[[".main[_ngcontent-%COMP%]{padding:0 3em}@media (max-width:720px){.main[_ngcontent-%COMP%]{padding:0 .5em}}blockquote[_ngcontent-%COMP%]{padding:0 22px;font-size:1.25rem;color:#616161;border-left:2px solid #e0e0e0;margin:0 0 1rem}"]],data:{}});function o(l){return e._23(0,[(l()(),e._4(0,0,null,null,177,"div",[["class","main"],["style","margin-top: 5em"]],null,null,null,null,null)),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(2,0,null,null,1,"h1",[["class","mat-h1"]],null,null,null,null,null)),(l()(),e._22(-1,null,["Fun little project"])),(l()(),e._22(-1,null,["\n  Or, instead of tackling the 'open questions' which are more relevant to my PhD, could have a bit of fun with:\n\n  "])),(l()(),e._4(5,0,null,null,1,"h1",[["class","mat-h1"],["id","maybe-drink"]],null,null,null,null,null)),(l()(),e._22(-1,null,["Maybe drink"])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(8,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e._22(-1,null,["/What are the chances"])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(11,0,null,null,1,"h2",[["class","mat-h2"],["id","approach"]],null,null,null,null,null)),(l()(),e._22(-1,null,["Approach"])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(14,0,null,null,13,"ol",[["type","1"]],null,null,null,null,null)),(l()(),e._22(-1,null,["\n    "])),(l()(),e._4(16,0,null,null,1,"li",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Take a map dataset"])),(l()(),e._22(-1,null,["\n    "])),(l()(),e._4(19,0,null,null,1,"li",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Look for all coffee shops (or whatever) [and maybe population densities]"])),(l()(),e._22(-1,null,["\n    "])),(l()(),e._4(22,0,null,null,1,"li",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Remove all coffee shops"])),(l()(),e._22(-1,null,["\n    "])),(l()(),e._4(25,0,null,null,1,"li",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Based on population densities in zoning rules, infer if there is a coffeeshop"])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(29,0,null,null,1,"h3",[["id","go-further"]],null,null,null,null,null)),(l()(),e._22(-1,null,["Go further"])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(32,0,null,null,10,"ol",[["start","5"],["type","1"]],null,null,null,null,null)),(l()(),e._22(-1,null,["\n    "])),(l()(),e._4(34,0,null,null,1,"li",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Search for coffee"])),(l()(),e._22(-1,null,["\n    "])),(l()(),e._4(37,0,null,null,1,"li",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Build an app"])),(l()(),e._22(-1,null,["\n    "])),(l()(),e._4(40,0,null,null,1,"li",[],null,null,null,null,null)),(l()(),e._22(-1,null,["As you\u2019re walking/driving along, it\u2019ll buzz and say \u201cthere probably a coffeeshop within 20 meters. 88.42%\n      coffeeshop; 70% grocery shop\u201d\n    "])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(44,0,null,null,1,"h3",[["id","generalise"]],null,null,null,null,null)),(l()(),e._22(-1,null,["Generalise"])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(47,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Actually let\u2019s generalise to specifying a single drink you care about. Now it\u2019s a find-me Lemonade app. Or a\n    find-me Kombucha app."])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(50,0,null,null,1,"h2",[["class","mat-h2"],["id","deliverables"]],null,null,null,null,null)),(l()(),e._22(-1,null,["Deliverables"])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(53,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e._22(-1,null,["In the course will build:"])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(56,0,null,null,13,"ol",[],null,null,null,null,null)),(l()(),e._22(-1,null,["\n    "])),(l()(),e._4(58,0,null,null,1,"li",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Fully functional neural network with a location->amenity dataset"])),(l()(),e._22(-1,null,["\n    "])),(l()(),e._4(61,0,null,null,1,"li",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Fully functional mobile app"])),(l()(),e._22(-1,null,["\n    "])),(l()(),e._4(64,0,null,null,1,"li",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Hacked-together scraper to quickly categorise a coffeeshop, but also include a simple NN for this task, to\n      cluster keywords (for later search)\n    "])),(l()(),e._22(-1,null,["\n    "])),(l()(),e._4(67,0,null,null,1,"li",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Near-realtime integration with the map and the mobile\u2019s GPS"])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(71,0,null,null,1,"h2",[["class","mat-h2"],["id","data-science-topics"]],null,null,null,null,null)),(l()(),e._22(-1,null,["Data science topics"])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(74,0,null,null,1,"h3",[["id","natural-language-processing-nlp"]],null,null,null,null,null)),(l()(),e._22(-1,null,["Natural Language Processing (NLP)"])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(77,0,null,null,4,"ul",[],null,null,null,null,null)),(l()(),e._22(-1,null,["\n    "])),(l()(),e._4(79,0,null,null,1,"li",[],null,null,null,null,null)),(l()(),e._22(-1,null,["NLP to categorise [disambiguate] drink based on country, e.g.: lemonade in Australia generally doesn\u2019t refer to\n      alcoholic beverages, whereas in America it does.\n    "])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(83,0,null,null,1,"h3",[["id","web-scraping"]],null,null,null,null,null)),(l()(),e._22(-1,null,["Web scraping"])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(86,0,null,null,7,"ul",[],null,null,null,null,null)),(l()(),e._22(-1,null,["\n    "])),(l()(),e._4(88,0,null,null,4,"li",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Given an OSM location, get the homepage, parse out the "])),(l()(),e._4(90,0,null,null,1,"code",[],null,null,null,null,null)),(l()(),e._22(-1,null,["<head>"])),(l()(),e._22(-1,null,[" and keyword search the body\n    "])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(95,0,null,null,1,"h3",[["id","multivariate-regression"]],null,null,null,null,null)),(l()(),e._22(-1,null,["Multivariate regression"])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(98,0,null,null,4,"ul",[],null,null,null,null,null)),(l()(),e._22(-1,null,["\n    "])),(l()(),e._4(100,0,null,null,1,"li",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Given a group of candidate stores, choose one most likely to have desired beverage"])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._22(-1,null,["\n\n\n  "])),(l()(),e._4(104,0,null,null,0,"hr",[],null,null,null,null,null)),(l()(),e._22(-1,null,["\n\n  "])),(l()(),e._4(106,0,null,null,1,"h1",[["class","mat-h1"]],null,null,null,null,null)),(l()(),e._22(-1,null,["Open questions"])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(109,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e._22(-1,null,["There are a few machine-learning research questions that I'm trying to solve in the short-term."])),(l()(),e._22(-1,null,["\n\n  "])),(l()(),e._4(112,0,null,null,1,"h2",[["class","mat-h2"]],null,null,null,null,null)),(l()(),e._22(-1,null,["Multivariate regression across medical images and patient records"])),(l()(),e._22(-1,null,["\n\n  "])),(l()(),e._4(115,0,null,null,1,"h4",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Idea 0"])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(118,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e._22(-1,null,["I was thinking that have a worker neural network doing the heavy lifting (maybe 3-5 NN all up) would do the\n    trick. To keep epochs manageable, was thinking about the Meta-Learning and One-Shot Learning literature. But maybe\n    that wouldn't\n    work?"])),(l()(),e._22(-1,null,["\n\n  "])),(l()(),e._4(121,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Here is an excerpt from an email I sent to an AI expert recently:"])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(124,0,null,null,19,"blockquote",[],null,null,null,null,null)),(l()(),e._22(-1,null,["\n    "])),(l()(),e._4(126,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Hey so was thinking, if you have a secondary neural network for optimising the first neural network, couldn't you\n      encode say image data in one, and patient data in another?"])),(l()(),e._22(-1,null,["\n\n    "])),(l()(),e._4(129,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Regularly we use multivariate regression\u2014potentially via neural networking\u2014on patient data to infer trends. For\n      the problems I work on, these are risk factors for developing blindness-causing diseases."])),(l()(),e._22(-1,null,["\n\n    "])),(l()(),e._4(132,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e._22(-1,null,["On the image side, I have a bunch of health and unhealthy images, and am currently just working out how to\n      segment the classification correctly (more of the time). But it is longitudinal data, so could always combine it\n      with information helping it say: these are healthy images for a patient that will become unhealthy."])),(l()(),e._22(-1,null,["\n\n    "])),(l()(),e._4(135,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e._22(-1,null,["On the text side, I have general demographic information like gender, age, ethnicity and a few more specific [to\n      glaucoma] metrics."])),(l()(),e._22(-1,null,["\n\n    "])),(l()(),e._4(138,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e._22(-1,null,["How would you combine these two datasets? - Such that given a new person walking off the street, we can emit one\n      number saying their probability of going blind in next k years (assuming no intervention)."])),(l()(),e._22(-1,null,["\n\n    "])),(l()(),e._4(141,0,null,null,1,"em",[],null,null,null,null,null)),(l()(),e._22(-1,null,["[multivariate regression over images and numerical patient data]"])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._22(-1,null,["\n\n  "])),(l()(),e._4(145,0,null,null,1,"h4",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Idea 1"])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(148,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Or maybe adding an extra channel to a convolutional neural network?"])),(l()(),e._22(-1,null,["\n\n  "])),(l()(),e._4(151,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Encode the patient data in a hidden channel. Maybe figure out encoding with spatial relevant, or just hack\n    specialised code for that last channel."])),(l()(),e._22(-1,null,["\n\n  "])),(l()(),e._4(154,0,null,null,1,"h4",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Idea 2"])),(l()(),e._22(-1,null,["\n  "])),(l()(),e._4(157,0,null,null,1,"p",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Jiquan Ngiam, Aditya Khosla, Mingyu Kim, Juhan Nam, Honglak Lee, and Andrew Y. Ng. 2011. Multimodal deep learning.\n    In Proceedings of the 28th International Conference on International Conference on Machine Learning (ICML'11), Lise\n    Getoor and Tobias Scheffer (Eds.). Omnipress, USA, 689-696."])),(l()(),e._22(-1,null,["\n\n  "])),(l()(),e._4(160,0,null,null,1,"h2",[["class","mat-h2"]],null,null,null,null,null)),(l()(),e._22(-1,null,["Expand existing glaucoma AI"])),(l()(),e._22(-1,null,["\n  Current Glaucoma CNN works on a non-public dataset (the "])),(l()(),e._4(163,0,null,null,1,"em",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Blue Mountains Eye Study"])),(l()(),e._22(-1,null,[").\n\n  "])),(l()(),e._4(166,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Idea 0: Transfer learning"])),(l()(),e._22(-1,null,["\n\n  "])),(l()(),e._4(169,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Idea 1: Incorporate public glaucoma datasets"])),(l()(),e._22(-1,null,["\n\n  "])),(l()(),e._4(172,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Idea 2: Incorporate NN for optic disc segmenetation"])),(l()(),e._22(-1,null,["\n  Sevastopolsky A., Optic disc and cup segmentation methods for glaucoma detection with modification of U-Net\n  convolutional neural network, Pattern Recognition and Image Analysis 27 (2017), no. 3, 618\u2013624.\n\n  "])),(l()(),e._4(175,0,null,null,1,"h3",[],null,null,null,null,null)),(l()(),e._22(-1,null,["Idea 3: Expand classifications to include Diabetic Retinopathy"])),(l()(),e._22(-1,null,["\n  See Kaggle competition open-source solutions for concepts + datasets.\n"])),(l()(),e._22(-1,null,["\n"]))],null,null)}var r=e._0("app-open-questions",t,function(l){return e._23(0,[(l()(),e._4(0,0,null,null,1,"app-open-questions",[],null,null,null,o,i)),e._3(1,114688,null,0,t,[],null,null)],function(l,n){l(n,1,0)},null)},{},{},[]),s=u("Xjw4"),_=u("bfOx");u.d(n,"OpenQuestionsModuleNgFactory",function(){return c});var c=e._1(a,[],function(l){return e._12([e._13(512,e.j,e.X,[[8,[r]],[3,e.j],e.v]),e._13(4608,s.l,s.k,[e.s,[2,s.v]]),e._13(512,s.b,s.b,[]),e._13(512,_.m,_.m,[[2,_.r],[2,_.k]]),e._13(512,a,a,[]),e._13(1024,_.i,function(){return[[{path:"",component:t}]]},[])])})}});