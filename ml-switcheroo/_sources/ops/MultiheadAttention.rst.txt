MultiheadAttention
==================

Multi-head attention mechanism.

**Abstract Signature:**

``MultiheadAttention(embed_dim, num_heads, dropout, bias, add_bias_kv, add_zero_attn, kdim, vdim, batch_first)``

.. raw:: html

 
    <div class="op-tabs-container"> 
      <div class="op-tabs-nav"> 
        <button class="op-tab-btn active" onclick="openOpTab(event, 'PyTorch_0')">PyTorch</button><button class="op-tab-btn " onclick="openOpTab(event, 'Keras_1')">Keras</button><button class="op-tab-btn " onclick="openOpTab(event, 'TensorFlow_2')">TensorFlow</button><button class="op-tab-btn " onclick="openOpTab(event, 'Apple MLX_3')">Apple MLX</button><button class="op-tab-btn " onclick="openOpTab(event, 'Flax NNX_4')">Flax NNX</button> 
      </div> 
      <div class="op-tabs-content"> 
        <div id="PyTorch_0" class="op-tab-pane active"><h4>PyTorch</h4><div class="op-detail-row"><span class="label">API:</span> <code>torch.nn.MultiheadAttention</code></div><div class="op-detail-row"><span class="label">Strategy:</span> <span>Direct Mapping</span></div><div class="op-detail-row"><a href="https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html" target="_blank" class="op-doc-link">Official Docs ↗</a></div></div><div id="Keras_1" class="op-tab-pane "><h4>Keras</h4><div class="op-detail-row"><span class="label">API:</span> <code>keras.layers.MultiHeadAttention</code></div><div class="op-detail-row"><span class="label">Strategy:</span> <span>Plugin (repack_attn_keras)</span></div></div><div id="TensorFlow_2" class="op-tab-pane "><h4>TensorFlow</h4><div class="op-detail-row"><span class="label">API:</span> <code>keras.layers.MultiHeadAttention</code></div><div class="op-detail-row"><span class="label">Strategy:</span> <span>Direct Mapping</span></div><div class="op-detail-row"><a href="https://www.tensorflow.org/api_docs/python/keras/layers/MultiHeadAttention" target="_blank" class="op-doc-link">Official Docs ↗</a></div></div><div id="Apple MLX_3" class="op-tab-pane "><h4>Apple MLX</h4><div class="op-detail-row"><span class="label">API:</span> <code>mlx.nn.layers.transformer.MultiHeadAttention</code></div><div class="op-detail-row"><span class="label">Strategy:</span> <span>Direct Mapping</span></div><div class="op-detail-row"><a href="https://ml-explore.github.io/mlx/build/html/python/_autosummary/mlx.nn.layers.transformer.MultiHeadAttention.html" target="_blank" class="op-doc-link">Official Docs ↗</a></div></div><div id="Flax NNX_4" class="op-tab-pane "><h4>Flax NNX</h4><div class="op-detail-row"><span class="label">API:</span> <code>flax.nnx.MultiHeadAttention</code></div><div class="op-detail-row"><span class="label">Strategy:</span> <span>Plugin (repack_attn_flax)</span></div></div> 
      </div> 

      <!-- Load JS Logic only once per page ideally, but safe to exist globally --> 
      <script src="../_static/op_tabs.js"></script> 
    </div> 

