ThresholdedRelu
===============

ThresholdedRelu takes one input data (Tensor<T>) and produces one output data (Tensor<T>) where the rectified linear function, y = x for x > alpha, y = 0 otherwise, is applied to the tensor elementwise.

**Abstract Signature:**

``ThresholdedRelu(X: Tensor, alpha: float)``

*No implementations mapped.*